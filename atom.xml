<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>你当像鸟飞往你的山</title>
  <icon>https://www.gravatar.com/avatar/e257bbdaac96306c21415b0151221195</icon>
  
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://yoursite.com/"/>
  <updated>2020-08-12T03:29:14.864Z</updated>
  <id>http://yoursite.com/</id>
  
  <author>
    <name>Xuefeng Tao</name>
    <email>tao642133424@163.com</email>
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>学习知乎实时数仓实践及架构演进</title>
    <link href="http://yoursite.com/2020/08/12/%E5%AD%A6%E4%B9%A0%E7%9F%A5%E4%B9%8E%E5%AE%9E%E6%97%B6%E6%95%B0%E4%BB%93%E5%AE%9E%E8%B7%B5%E5%8F%8A%E6%9E%B6%E6%9E%84%E6%BC%94%E8%BF%9B/"/>
    <id>http://yoursite.com/2020/08/12/%E5%AD%A6%E4%B9%A0%E7%9F%A5%E4%B9%8E%E5%AE%9E%E6%97%B6%E6%95%B0%E4%BB%93%E5%AE%9E%E8%B7%B5%E5%8F%8A%E6%9E%B6%E6%9E%84%E6%BC%94%E8%BF%9B/</id>
    <published>2020-08-12T02:49:20.000Z</published>
    <updated>2020-08-12T03:29:14.864Z</updated>
    
    <summary type="html">
    
      &lt;h1 id=&quot;前言&quot;&gt;&lt;a href=&quot;#前言&quot; class=&quot;headerlink&quot; title=&quot;前言&quot;&gt;&lt;/a&gt;前言&lt;/h1&gt;&lt;p&gt;“数据智能” (Data Intelligence) 有一个必须且基础的环节，就是数据仓库的建设，同时，数据仓库也是公司数据发展到一定规模后必然会提供的一种基础服务。从智能商业的角度来讲，数据的结果代表了用户的反馈，获取结果的及时性就显得尤为重要，快速的获取数据反馈能够帮助公司更快的做出决策，更好的进行产品迭代，实时数仓在这一过程中起到了不可替代的作用。&lt;/p&gt;
&lt;p&gt;本文主要讲述知乎的实时数仓实践以及架构的演进，这包括以下几个方面&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;p&gt;实时数仓 1.0 版本，主题： ETL 逻辑实时化，技术方案：Spark Streaming。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;实时数仓 2.0 版本，主题：数据分层，指标计算实时化，技术方案：Flink Streaming。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;实时数仓未来展望：Streaming SQL 平台化，元信息管理系统化，结果验收自动化。&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;
    
    </summary>
    
    
      <category term="实时数仓" scheme="http://yoursite.com/categories/%E5%AE%9E%E6%97%B6%E6%95%B0%E4%BB%93/"/>
    
    
      <category term="学习笔记" scheme="http://yoursite.com/tags/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
      <category term="实时计算" scheme="http://yoursite.com/tags/%E5%AE%9E%E6%97%B6%E8%AE%A1%E7%AE%97/"/>
    
      <category term="实时数仓" scheme="http://yoursite.com/tags/%E5%AE%9E%E6%97%B6%E6%95%B0%E4%BB%93/"/>
    
  </entry>
  
  <entry>
    <title>实时数仓</title>
    <link href="http://yoursite.com/2020/08/11/%E5%AE%9E%E6%97%B6%E6%95%B0%E4%BB%93/"/>
    <id>http://yoursite.com/2020/08/11/%E5%AE%9E%E6%97%B6%E6%95%B0%E4%BB%93/</id>
    <published>2020-08-11T03:47:16.000Z</published>
    <updated>2020-08-11T05:43:03.618Z</updated>
    
    <summary type="html">
    
      &lt;h3 id=&quot;0x00-数仓为什么要实时&quot;&gt;&lt;a href=&quot;#0x00-数仓为什么要实时&quot; class=&quot;headerlink&quot; title=&quot;|0x00 数仓为什么要实时&quot;&gt;&lt;/a&gt;|0x00 数仓为什么要实时&lt;/h3&gt;&lt;p&gt;去年开始，&lt;font color=&quot;red&quot;&gt;实时数仓&lt;/font&gt; 的概念突然火了。也许是&lt;strong&gt;传统的离线数仓搞了很多年&lt;/strong&gt;，技术相对成熟了，因此大家都把注意力放到了&lt;strong&gt;挑战性更高&lt;/strong&gt;的实时上来；也许是随着&lt;strong&gt;存量市场竞争&lt;/strong&gt;的到来，对于速度的要求越来越快，&lt;strong&gt;T+1已经不能满足数据的获取要求了&lt;/strong&gt;，实时的构建需求也就应运而生了。 &lt;/p&gt;
&lt;p&gt;&lt;font color=&quot;red&quot;&gt;总之，时效性开始大于分析性&lt;/font&gt; 。&lt;/p&gt;
&lt;p&gt;文本简单介绍实时数仓的一些基础理论，更系统性的理论，仍然行业需要更大范围的应用和总结。总之，这是一块&lt;strong&gt;有前景&lt;/strong&gt;的&lt;strong&gt;新领域&lt;/strong&gt;，值得探索。&lt;/p&gt;
    
    </summary>
    
    
      <category term="实时数仓" scheme="http://yoursite.com/categories/%E5%AE%9E%E6%97%B6%E6%95%B0%E4%BB%93/"/>
    
    
      <category term="数仓" scheme="http://yoursite.com/tags/%E6%95%B0%E4%BB%93/"/>
    
      <category term="实时" scheme="http://yoursite.com/tags/%E5%AE%9E%E6%97%B6/"/>
    
  </entry>
  
  <entry>
    <title>Hbase学习笔记-1</title>
    <link href="http://yoursite.com/2020/08/04/Hbase%E7%AC%94%E8%AE%B0-1/"/>
    <id>http://yoursite.com/2020/08/04/Hbase%E7%AC%94%E8%AE%B0-1/</id>
    <published>2020-08-04T11:47:45.000Z</published>
    <updated>2020-08-07T10:30:45.607Z</updated>
    
    <summary type="html">
    
      &lt;h2 id=&quot;一-Hadoop的局限性&quot;&gt;&lt;a href=&quot;#一-Hadoop的局限性&quot; class=&quot;headerlink&quot; title=&quot;一.Hadoop的局限性&quot;&gt;&lt;/a&gt;一.Hadoop的局限性&lt;/h2&gt;&lt;p&gt;Hbase是一个构建在Hadoop文件系统之上的面向列(列族)的数据库管理系统&lt;/p&gt;
&lt;img src=&quot;/2020/08/04/Hbase%E7%AC%94%E8%AE%B0-1/image-20200804194929543.png&quot; alt=&quot;image-20200804194929543&quot; style=&quot;zoom:50%;&quot;&gt;
    
    </summary>
    
    
      <category term="Hbase" scheme="http://yoursite.com/categories/Hbase/"/>
    
    
      <category term="Hbase" scheme="http://yoursite.com/tags/Hbase/"/>
    
      <category term="学习笔记" scheme="http://yoursite.com/tags/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
  </entry>
  
  <entry>
    <title>MapReduce小文件优化问题</title>
    <link href="http://yoursite.com/2020/08/04/MapReduce%E5%B0%8F%E6%96%87%E4%BB%B6%E4%BC%98%E5%8C%96%E9%97%AE%E9%A2%98/"/>
    <id>http://yoursite.com/2020/08/04/MapReduce%E5%B0%8F%E6%96%87%E4%BB%B6%E4%BC%98%E5%8C%96%E9%97%AE%E9%A2%98/</id>
    <published>2020-08-04T11:42:41.000Z</published>
    <updated>2020-08-04T11:45:19.506Z</updated>
    
    <summary type="html">
    
      &lt;p&gt;默认情况下，TextInputformat对任务的切片机智是按文件规划切片，不管文件多小，都会是一个单独的切片，都是交给一个maptask，如果有多个小文件，就会产生大量的maptask，处理效率底下。&lt;/p&gt;
    
    </summary>
    
    
      <category term="MapReduce" scheme="http://yoursite.com/categories/MapReduce/"/>
    
    
      <category term="优化" scheme="http://yoursite.com/tags/%E4%BC%98%E5%8C%96/"/>
    
  </entry>
  
  <entry>
    <title>机器学习项目01-鸢尾花分类</title>
    <link href="http://yoursite.com/2020/07/24/ML-flower/"/>
    <id>http://yoursite.com/2020/07/24/ML-flower/</id>
    <published>2020-07-24T10:32:57.000Z</published>
    <updated>2020-07-24T11:20:42.263Z</updated>
    
    <summary type="html">
    
      &lt;p&gt;机器学习项目之鸢尾花分类:&lt;/p&gt;
&lt;h3 id=&quot;任务描述&quot;&gt;&lt;a href=&quot;#任务描述&quot; class=&quot;headerlink&quot; title=&quot;任务描述:&quot;&gt;&lt;/a&gt;任务描述:&lt;/h3&gt;&lt;p&gt;构建一个模型，根据鸢尾花的花萼和花瓣大小将其分为三种不同的品种。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/2020/07/24/ML-flower/dd74666475b549fcae99ac2aff67488f015cdd76569d4d208909983bcf40fe3c.png&quot; alt=&quot;dd74666475b549fcae99ac2aff67488f015cdd76569d4d208909983bcf40fe3c&quot;&gt;&lt;/p&gt;
    
    </summary>
    
    
      <category term="机器学习" scheme="http://yoursite.com/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="鸢尾花分类" scheme="http://yoursite.com/tags/%E9%B8%A2%E5%B0%BE%E8%8A%B1%E5%88%86%E7%B1%BB/"/>
    
      <category term="机器学习" scheme="http://yoursite.com/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="Notebook" scheme="http://yoursite.com/tags/Notebook/"/>
    
  </entry>
  
  <entry>
    <title>同比与环比</title>
    <link href="http://yoursite.com/2020/07/24/%E5%90%8C%E6%AF%94%E7%8E%AF%E6%AF%94/"/>
    <id>http://yoursite.com/2020/07/24/%E5%90%8C%E6%AF%94%E7%8E%AF%E6%AF%94/</id>
    <published>2020-07-24T10:12:57.000Z</published>
    <updated>2020-07-24T11:07:04.052Z</updated>
    
    <summary type="html">
    
      &lt;h2 id=&quot;概念&quot;&gt;&lt;a href=&quot;#概念&quot; class=&quot;headerlink&quot; title=&quot;概念&quot;&gt;&lt;/a&gt;概念&lt;/h2&gt;&lt;p&gt;同比：本期与同期做对比。&lt;/p&gt;
&lt;p&gt;环比：本期与上期做对比。&lt;/p&gt;
&lt;p&gt;简单点说，同比和环比用于表示某一事物在对比时期内发展变化的方向和程度。以历史同期为基期，例如2016年2月份与2015年2月份、2016年上半年与2015年上半年的比较，就是同比。以前一个统计时间段为基期，例如2016年6月份与2016年5月份、2016年二季度与2016年一季度的比较，就是环比。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/2020/07/24/%E5%90%8C%E6%AF%94%E7%8E%AF%E6%AF%94/c5EoSijy31QIDAx.png&quot; alt=&quot;c5EoSijy31QIDAx&quot;&gt;&lt;/p&gt;
    
    </summary>
    
    
      <category term="数据" scheme="http://yoursite.com/categories/%E6%95%B0%E6%8D%AE/"/>
    
    
      <category term="同比/环比" scheme="http://yoursite.com/tags/%E5%90%8C%E6%AF%94-%E7%8E%AF%E6%AF%94/"/>
    
  </entry>
  
  <entry>
    <title>mac连接公司vpn的坑</title>
    <link href="http://yoursite.com/2020/07/24/mac%E8%BF%9E%E6%8E%A5%E5%85%AC%E5%8F%B8VPN%E7%9A%84%E5%9D%91/"/>
    <id>http://yoursite.com/2020/07/24/mac%E8%BF%9E%E6%8E%A5%E5%85%AC%E5%8F%B8VPN%E7%9A%84%E5%9D%91/</id>
    <published>2020-07-24T09:12:57.000Z</published>
    <updated>2020-07-24T11:18:28.001Z</updated>
    
    <summary type="html">
    
      &lt;h3 id=&quot;问题&quot;&gt;&lt;a href=&quot;#问题&quot; class=&quot;headerlink&quot; title=&quot;问题&quot;&gt;&lt;/a&gt;问题&lt;/h3&gt;&lt;p&gt;1.出现IPSec共享密匙丢失&lt;/p&gt;
&lt;p&gt;2.能访问公司内网,无法访问公网&lt;/p&gt;
    
    </summary>
    
    
      <category term="公司vpn" scheme="http://yoursite.com/categories/%E5%85%AC%E5%8F%B8vpn/"/>
    
    
      <category term="远程访问" scheme="http://yoursite.com/tags/%E8%BF%9C%E7%A8%8B%E8%AE%BF%E9%97%AE/"/>
    
      <category term="公司vpn" scheme="http://yoursite.com/tags/%E5%85%AC%E5%8F%B8vpn/"/>
    
  </entry>
  
  <entry>
    <title>hive on spark与spark on hive的区别</title>
    <link href="http://yoursite.com/2020/07/23/Hive-on-Spark%E4%B8%8ESparkSql%E7%9A%84%E5%8C%BA%E5%88%AB/"/>
    <id>http://yoursite.com/2020/07/23/Hive-on-Spark%E4%B8%8ESparkSql%E7%9A%84%E5%8C%BA%E5%88%AB/</id>
    <published>2020-07-23T09:12:57.000Z</published>
    <updated>2020-07-24T11:15:36.500Z</updated>
    
    <summary type="html">
    
      &lt;h3 id=&quot;SparkSQL简介&quot;&gt;&lt;a href=&quot;#SparkSQL简介&quot; class=&quot;headerlink&quot; title=&quot;SparkSQL简介&quot;&gt;&lt;/a&gt;SparkSQL简介&lt;/h3&gt;&lt;p&gt;SparkSQL的前身是Shark，给熟悉RDBMS但又不理解MapReduce的技术人员提供快速上手的工具，hive应运而生，它是当时唯一运行在Hadoop上的SQL-on-hadoop工具。但是MapReduce计算过程中大量的中间磁盘落地过程消耗了大量的I/O，降低的运行效率，为了提高SQL-on-Hadoop的效率，Shark应运而生，但又因为Shark对于Hive的太多依赖（如采用Hive的语法解析器、查询优化器等等),2014年spark团队停止对Shark的开发，将所有资源放SparkSQL项目上&lt;/p&gt;
    
    </summary>
    
    
      <category term="Hive" scheme="http://yoursite.com/categories/Hive/"/>
    
    
      <category term="hive on spark" scheme="http://yoursite.com/tags/hive-on-spark/"/>
    
      <category term="spark on hive" scheme="http://yoursite.com/tags/spark-on-hive/"/>
    
  </entry>
  
  <entry>
    <title>hive两个聚合函数的计算结果拼接成表并做进一步计算</title>
    <link href="http://yoursite.com/2020/07/23/%E4%B8%A4%E4%B8%AA%E8%81%9A%E5%90%88%E5%87%BD%E6%95%B0%E8%AE%A1%E7%AE%97%E7%BB%93%E6%9E%9C%E8%BF%9B%E8%A1%8C%E6%8B%BC%E6%8E%A5/"/>
    <id>http://yoursite.com/2020/07/23/%E4%B8%A4%E4%B8%AA%E8%81%9A%E5%90%88%E5%87%BD%E6%95%B0%E8%AE%A1%E7%AE%97%E7%BB%93%E6%9E%9C%E8%BF%9B%E8%A1%8C%E6%8B%BC%E6%8E%A5/</id>
    <published>2020-07-23T04:12:57.000Z</published>
    <updated>2020-07-23T03:51:12.106Z</updated>
    
    <summary type="html">
    
      &lt;h4 id=&quot;hive两个聚合函数的计算结果拼接成表并做进一步计算&quot;&gt;&lt;a href=&quot;#hive两个聚合函数的计算结果拼接成表并做进一步计算&quot; class=&quot;headerlink&quot; title=&quot;hive两个聚合函数的计算结果拼接成表并做进一步计算&quot;&gt;&lt;/a&gt;hive两个聚合函数的计算结果拼接成表并做进一步计算&lt;/h4&gt;&lt;p&gt;hive两个聚合函数的计算结果拼接成表让LZ头疼了很久，一度想到用python处理，或者新建两张临时表保存聚合函数的结果然后再取出数据进行计算，或者使用UDF, 但总觉得还有其他方法。经过一番探索，发现WITH AS 可以方便快捷解决此问题。&lt;/p&gt;
    
    </summary>
    
    
      <category term="Hive" scheme="http://yoursite.com/categories/Hive/"/>
    
    
      <category term="hive" scheme="http://yoursite.com/tags/hive/"/>
    
      <category term="函数" scheme="http://yoursite.com/tags/%E5%87%BD%E6%95%B0/"/>
    
  </entry>
  
  <entry>
    <title>Parquet列式存储格式</title>
    <link href="http://yoursite.com/2020/07/22/parquet%E5%88%97%E5%BC%8F%E5%AD%98%E5%82%A8%E6%A0%BC%E5%BC%8F/"/>
    <id>http://yoursite.com/2020/07/22/parquet%E5%88%97%E5%BC%8F%E5%AD%98%E5%82%A8%E6%A0%BC%E5%BC%8F/</id>
    <published>2020-07-22T11:40:53.000Z</published>
    <updated>2020-07-22T11:41:15.332Z</updated>
    
    <summary type="html">
    
      &lt;p&gt;Parquet是面向分析型业务的列式存储格式，由Twitter和Cloudera合作开发，2015年5月从Apache的孵化器里毕业成为Apache顶级项目，最新的版本是1.8.0。&lt;/p&gt;
    
    </summary>
    
    
      <category term="Parquet" scheme="http://yoursite.com/categories/Parquet/"/>
    
    
      <category term="hive" scheme="http://yoursite.com/tags/hive/"/>
    
      <category term="Parquet" scheme="http://yoursite.com/tags/Parquet/"/>
    
  </entry>
  
  <entry>
    <title>Hive中Parquet格式的使用</title>
    <link href="http://yoursite.com/2020/07/22/Hive%E4%B8%ADParquet%E6%A0%BC%E5%BC%8F%E7%9A%84%E4%BD%BF%E7%94%A8/"/>
    <id>http://yoursite.com/2020/07/22/Hive%E4%B8%ADParquet%E6%A0%BC%E5%BC%8F%E7%9A%84%E4%BD%BF%E7%94%A8/</id>
    <published>2020-07-22T11:38:48.000Z</published>
    <updated>2020-07-22T11:40:19.675Z</updated>
    
    <summary type="html">
    
      &lt;h1 id=&quot;Hive中Parquet格式的使用&quot;&gt;&lt;a href=&quot;#Hive中Parquet格式的使用&quot; class=&quot;headerlink&quot; title=&quot;Hive中Parquet格式的使用&quot;&gt;&lt;/a&gt;Hive中Parquet格式的使用&lt;/h1&gt;&lt;p&gt;&lt;strong&gt;#Hive建外部External表（外部表external table）：&lt;/strong&gt;&lt;/p&gt;
&lt;figure class=&quot;highlight sql&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;12&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;13&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;14&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;15&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;CREATE&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;EXTERNAL&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;TABLE&lt;/span&gt; &lt;span class=&quot;string&quot;&gt;`table_name`&lt;/span&gt;(&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;  &lt;span class=&quot;string&quot;&gt;`column1`&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;string&lt;/span&gt;,&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;  &lt;span class=&quot;string&quot;&gt;`column2`&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;string&lt;/span&gt;,&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;  &lt;span class=&quot;string&quot;&gt;`column3`&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;string&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;PARTITIONED &lt;span class=&quot;keyword&quot;&gt;BY&lt;/span&gt; (&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;  &lt;span class=&quot;string&quot;&gt;`proc_date`&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;string&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;ROW&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;FORMAT&lt;/span&gt; SERDE&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;  &lt;span class=&quot;string&quot;&gt;&#39;org.apache.hadoop.hive.ql.io.parquet.serde.ParquetHiveSerDe&#39;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;STORED&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;AS&lt;/span&gt; INPUTFORMAT&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;  &lt;span class=&quot;string&quot;&gt;&#39;org.apache.hadoop.hive.ql.io.parquet.MapredParquetInputFormat&#39;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;OUTPUTFORMAT&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;  &lt;span class=&quot;string&quot;&gt;&#39;org.apache.hadoop.hive.ql.io.parquet.MapredParquetOutputFormat&#39;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;LOCATION&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;  &lt;span class=&quot;string&quot;&gt;&#39;hdfs://hdfscluster/...&#39;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;TBLPROPERTIES ( &lt;span class=&quot;string&quot;&gt;&#39;orc.compress&#39;&lt;/span&gt;=&lt;span class=&quot;string&quot;&gt;&#39;snappy&#39;&lt;/span&gt;);&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
    
    </summary>
    
    
      <category term="Hive" scheme="http://yoursite.com/categories/Hive/"/>
    
    
      <category term="hive" scheme="http://yoursite.com/tags/hive/"/>
    
      <category term="Parquet" scheme="http://yoursite.com/tags/Parquet/"/>
    
  </entry>
  
  <entry>
    <title>Python时间操作</title>
    <link href="http://yoursite.com/2020/07/22/python%E6%97%B6%E9%97%B4/"/>
    <id>http://yoursite.com/2020/07/22/python%E6%97%B6%E9%97%B4/</id>
    <published>2020-07-22T11:34:19.000Z</published>
    <updated>2020-07-22T11:37:39.354Z</updated>
    
    <summary type="html">
    
      &lt;figure class=&quot;highlight python&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;import&lt;/span&gt; time&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;print&lt;/span&gt; time.time()	&lt;span class=&quot;comment&quot;&gt;#输出的结果是:1279578704.6725271&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
    
    </summary>
    
    
      <category term="语言" scheme="http://yoursite.com/categories/%E8%AF%AD%E8%A8%80/"/>
    
    
      <category term="python" scheme="http://yoursite.com/tags/python/"/>
    
  </entry>
  
  <entry>
    <title>Sqoop从mysql导入数据到hive</title>
    <link href="http://yoursite.com/2020/07/22/sqoop%E4%BB%8Emysql%E5%AF%BC%E5%85%A5%E6%95%B0%E6%8D%AE%E5%88%B0hive/"/>
    <id>http://yoursite.com/2020/07/22/sqoop%E4%BB%8Emysql%E5%AF%BC%E5%85%A5%E6%95%B0%E6%8D%AE%E5%88%B0hive/</id>
    <published>2020-07-22T06:12:02.000Z</published>
    <updated>2020-07-22T06:25:09.346Z</updated>
    
    <summary type="html">
    
      &lt;h2 id=&quot;一、简介&quot;&gt;&lt;a href=&quot;#一、简介&quot; class=&quot;headerlink&quot; title=&quot;一、简介&quot;&gt;&lt;/a&gt;一、简介&lt;/h2&gt;&lt;p&gt;Sqoop是一个用来将Hadoop和关系型数据库中的数据相互转移的工具，可以将一个关系型数据库（例如 ： MySQL ,Oracle ,Postgres等）中的数据导进到Hadoop的HDFS中，也可以将HDFS的数据导进到关系型数据库中。Sqoop专为大数据批量传输设计，能够分割数据集并创建Hadoop任务来处理每个区块。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;把MySQL、Oracle等数据库中的数据导入到HDFS、Hive、HBase中。
把HDFS、Hive、HBase中的数据导出到MySQL、Oracle等数据库中。
1.4 为sqoop1, 1.9 为sqoop2 ，sqoop1与sqoop2是不兼容的。&lt;/code&gt;&lt;/pre&gt;
    
    </summary>
    
    
      <category term="Sqoop" scheme="http://yoursite.com/categories/Sqoop/"/>
    
    
      <category term="hive" scheme="http://yoursite.com/tags/hive/"/>
    
      <category term="Sqoop" scheme="http://yoursite.com/tags/Sqoop/"/>
    
      <category term="mysql" scheme="http://yoursite.com/tags/mysql/"/>
    
  </entry>
  
  <entry>
    <title>逻辑主键,业务主键和复合主键</title>
    <link href="http://yoursite.com/2020/07/21/%E9%80%BB%E8%BE%91%E4%B8%BB%E9%94%AE,%E4%B8%9A%E5%8A%A1%E4%B8%BB%E9%94%AE%E5%92%8C%E5%A4%8D%E5%90%88%E4%B8%BB%E9%94%AE/"/>
    <id>http://yoursite.com/2020/07/21/%E9%80%BB%E8%BE%91%E4%B8%BB%E9%94%AE,%E4%B8%9A%E5%8A%A1%E4%B8%BB%E9%94%AE%E5%92%8C%E5%A4%8D%E5%90%88%E4%B8%BB%E9%94%AE/</id>
    <published>2020-07-21T14:40:53.000Z</published>
    <updated>2020-07-22T14:32:23.774Z</updated>
    
    <summary type="html">
    
      &lt;p&gt;&lt;strong&gt;1.概念定义&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;a href=&quot;http://msdn.microsoft.com/zh-cn/library/ms191236(v=SQL.100).aspx&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;主键(PRIMARY KEY)&lt;/a&gt;：表通常具有包含唯一标识表中每一行的值的一列或一组列。这样的一列或多列称为表的主键 (PK)，用于强制表的实体完整性。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;a href=&quot;http://msdn.microsoft.com/zh-cn/library/ms175464(v=SQL.100).aspx&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;外键(FOREIGN KEY)&lt;/a&gt;：外键 (FK) 是用于建立和加强两个表数据之间的链接的一列或多列。在外键引用中，当一个表的列被引用作为另一个表的主键值的列时，就在两表之间创建了链接。这个列就成为第二个表的外键。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;a href=&quot;http://msdn.microsoft.com/zh-cn/library/ms190639(v=SQL.100).aspx&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;聚集索引&lt;/a&gt;：聚集索引基于数据行的键值在表内排序和存储这些数据行。每个表只能有一个聚集索引，因为数据行本身只能按一个顺序存储。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;a href=&quot;http://msdn.microsoft.com/zh-cn/library/ms179325(v=SQL.100).aspx&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;非聚集索引&lt;/a&gt;：非聚集索引包含索引键值和指向表数据存储位置的行定位器。可以对表或索引视图创建多个非聚集索引。通常，设计非聚集索引是为改善经常使用的、没有建立聚集索引的查询的性能。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;a href=&quot;http://msdn.microsoft.com/zh-cn/library/ms179413(v=SQL.100).aspx&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;自动编号列和标识符列&lt;/a&gt;：对于每个表，均可创建一个包含系统生成的序号值的标识符列，该序号值以唯一方式标识表中的每一行。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;业务主键（自然主键）：在数据库表中把具有业务逻辑含义的字段作为主键，称为“自然主键(Natural Key)”。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;逻辑主键（代理主键）：在数据库表中采用一个与当前表中逻辑信息无关的字段作为其主键，称为“代理主键”。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;复合主键（联合主键）：通过两个或者多个字段的组合作为主键。&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;
    
    </summary>
    
    
      <category term="数仓" scheme="http://yoursite.com/categories/%E6%95%B0%E4%BB%93/"/>
    
    
      <category term="hive" scheme="http://yoursite.com/tags/hive/"/>
    
      <category term="主键" scheme="http://yoursite.com/tags/%E4%B8%BB%E9%94%AE/"/>
    
  </entry>
  
  <entry>
    <title>hive2的启动</title>
    <link href="http://yoursite.com/2020/06/26/hive2%E6%9C%8D%E5%8A%A1/"/>
    <id>http://yoursite.com/2020/06/26/hive2%E6%9C%8D%E5%8A%A1/</id>
    <published>2020-06-26T04:12:57.000Z</published>
    <updated>2020-07-24T10:31:25.790Z</updated>
    
    <summary type="html">
    
      
      
        
        
          &lt;ol&gt;
&lt;li&gt;启动hive的服务&lt;br&gt;hive ‐‐service hiveserver2 &amp;amp;&lt;/li&gt;
&lt;li&gt;使用beeline，去连接thrift的服务&lt;br&gt;beeline -u
        
      
    
    </summary>
    
    
      <category term="Hive" scheme="http://yoursite.com/categories/Hive/"/>
    
    
      <category term="hive" scheme="http://yoursite.com/tags/hive/"/>
    
      <category term="服务" scheme="http://yoursite.com/tags/%E6%9C%8D%E5%8A%A1/"/>
    
      <category term="beeline" scheme="http://yoursite.com/tags/beeline/"/>
    
  </entry>
  
  <entry>
    <title>数据质量检查</title>
    <link href="http://yoursite.com/2020/06/26/%E6%95%B0%E6%8D%AE%E8%B4%A8%E9%87%8F%E6%A3%80%E6%9F%A5/"/>
    <id>http://yoursite.com/2020/06/26/%E6%95%B0%E6%8D%AE%E8%B4%A8%E9%87%8F%E6%A3%80%E6%9F%A5/</id>
    <published>2020-06-26T04:12:57.000Z</published>
    <updated>2020-07-27T16:15:38.548Z</updated>
    
    <summary type="html">
    
      &lt;h1 id=&quot;1-数据质量检查&quot;&gt;&lt;a href=&quot;#1-数据质量检查&quot; class=&quot;headerlink&quot; title=&quot;1.数据质量检查&quot;&gt;&lt;/a&gt;1.数据质量检查&lt;/h1&gt;&lt;p&gt;是在完成宽表数据开发后进行的，主要包括四个方面：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;p&gt;重复值检查&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;缺失值检查&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;数据倾斜问题&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;异常值检查&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;
    
    </summary>
    
    
      <category term="数据" scheme="http://yoursite.com/categories/%E6%95%B0%E6%8D%AE/"/>
    
    
      <category term="质量检查" scheme="http://yoursite.com/tags/%E8%B4%A8%E9%87%8F%E6%A3%80%E6%9F%A5/"/>
    
      <category term="数仓" scheme="http://yoursite.com/tags/%E6%95%B0%E4%BB%93/"/>
    
      <category term="数据质量" scheme="http://yoursite.com/tags/%E6%95%B0%E6%8D%AE%E8%B4%A8%E9%87%8F/"/>
    
  </entry>
  
</feed>
