<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>你当像鸟飞往你的山</title>
  <icon>https://www.gravatar.com/avatar/e257bbdaac96306c21415b0151221195</icon>
  
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://yoursite.com/"/>
  <updated>2020-09-02T09:59:37.350Z</updated>
  <id>http://yoursite.com/</id>
  
  <author>
    <name>Xuefeng Tao</name>
    <email>tao642133424@163.com</email>
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>Hive SQl</title>
    <link href="http://yoursite.com/2020/09/01/Hive-SQl/"/>
    <id>http://yoursite.com/2020/09/01/Hive-SQl/</id>
    <published>2020-09-01T05:52:54.000Z</published>
    <updated>2020-09-02T09:59:37.350Z</updated>
    
    <summary type="html">
    
      &lt;h3 id=&quot;添加分区&quot;&gt;&lt;a href=&quot;#添加分区&quot; class=&quot;headerlink&quot; title=&quot;添加分区&quot;&gt;&lt;/a&gt;添加分区&lt;/h3&gt;&lt;figure class=&quot;highlight java&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;function&quot;&gt;ALTER TABLE table_name ADD &lt;span class=&quot;title&quot;&gt;PARTITION&lt;/span&gt; &lt;span class=&quot;params&quot;&gt;(partCol = &lt;span class=&quot;string&quot;&gt;&#39;value1&#39;&lt;/span&gt;)&lt;/span&gt; location &#39;loc1&#39;&lt;/span&gt;; &lt;span class=&quot;comment&quot;&gt;//示例&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;function&quot;&gt;ALTER TABLE table_name ADD IF NOT EXISTS &lt;span class=&quot;title&quot;&gt;PARTITION&lt;/span&gt; &lt;span class=&quot;params&quot;&gt;(dt=&lt;span class=&quot;string&quot;&gt;&#39;20130101&#39;&lt;/span&gt;)&lt;/span&gt; LOCATION &#39;/user/hadoop/warehouse/table_name/dt&lt;/span&gt;=&lt;span class=&quot;number&quot;&gt;20130101&lt;/span&gt;&lt;span class=&quot;string&quot;&gt;&#39;; //一次添加一个分区&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;string&quot;&gt;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;string&quot;&gt;ALTER TABLE page_view ADD PARTITION (dt=&#39;&lt;/span&gt;&lt;span class=&quot;number&quot;&gt;2008&lt;/span&gt;-&lt;span class=&quot;number&quot;&gt;08&lt;/span&gt;-&lt;span class=&quot;number&quot;&gt;08&lt;/span&gt;&lt;span class=&quot;string&quot;&gt;&#39;, country=&#39;&lt;/span&gt;us&lt;span class=&quot;string&quot;&gt;&#39;) location &#39;&lt;/span&gt;/path/to/us/part080808&lt;span class=&quot;string&quot;&gt;&#39; PARTITION (dt=&#39;&lt;/span&gt;&lt;span class=&quot;number&quot;&gt;2008&lt;/span&gt;-&lt;span class=&quot;number&quot;&gt;08&lt;/span&gt;-&lt;span class=&quot;number&quot;&gt;09&lt;/span&gt;&lt;span class=&quot;string&quot;&gt;&#39;, country=&#39;&lt;/span&gt;us&lt;span class=&quot;string&quot;&gt;&#39;) location &#39;&lt;/span&gt;/path/to/us/part080809&lt;span class=&quot;string&quot;&gt;&#39;;  //一次添加多个分区&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
    
    </summary>
    
    
      <category term="Hive" scheme="http://yoursite.com/categories/Hive/"/>
    
    
      <category term="hive" scheme="http://yoursite.com/tags/hive/"/>
    
      <category term="sql" scheme="http://yoursite.com/tags/sql/"/>
    
  </entry>
  
  <entry>
    <title>Spark数据倾斜处理方法总结</title>
    <link href="http://yoursite.com/2020/08/24/Spark%E6%95%B0%E6%8D%AE%E5%80%BE%E6%96%9C%E5%A4%84%E7%90%86%E6%96%B9%E6%B3%95%E6%80%BB%E7%BB%93/"/>
    <id>http://yoursite.com/2020/08/24/Spark%E6%95%B0%E6%8D%AE%E5%80%BE%E6%96%9C%E5%A4%84%E7%90%86%E6%96%B9%E6%B3%95%E6%80%BB%E7%BB%93/</id>
    <published>2020-08-24T07:53:57.000Z</published>
    <updated>2020-08-24T08:06:38.617Z</updated>
    
    <summary type="html">
    
      &lt;h2 id=&quot;Spark性能优化之道——解决Spark数据倾斜（Data-Skew）的N种姿势&quot;&gt;&lt;a href=&quot;#Spark性能优化之道——解决Spark数据倾斜（Data-Skew）的N种姿势&quot; class=&quot;headerlink&quot; title=&quot;Spark性能优化之道——解决Spark数据倾斜（Data Skew）的N种姿势&quot;&gt;&lt;/a&gt;Spark性能优化之道——解决Spark数据倾斜（Data Skew）的N种姿势&lt;/h2&gt;&lt;p&gt;本文结合实例详细阐明了Spark数据倾斜的几种场景以及对应的解决方案，包括避免数据源倾斜，调整并行度，使用自定义Partitioner，使用Map侧Join代替Reduce侧Join，给倾斜Key加上随机前缀等。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;  本文转发自技术世界，原文链接&lt;a href=&quot;http://www.jasongj.com/spark/skew/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;http://www.jasongj.com/spark/skew/&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h1 id=&quot;摘要&quot;&gt;&lt;a href=&quot;#摘要&quot; class=&quot;headerlink&quot; title=&quot;摘要&quot;&gt;&lt;/a&gt;摘要&lt;/h1&gt;&lt;p&gt;本文结合实例详细阐明了Spark数据倾斜的几种场景以及对应的解决方案，包括避免数据源倾斜，调整并行度，使用自定义Partitioner，使用Map侧Join代替Reduce侧Join，给倾斜Key加上随机前缀等。&lt;/p&gt;
&lt;h1 id=&quot;为何要处理数据倾斜（Data-Skew）&quot;&gt;&lt;a href=&quot;#为何要处理数据倾斜（Data-Skew）&quot; class=&quot;headerlink&quot; title=&quot;为何要处理数据倾斜（Data Skew）&quot;&gt;&lt;/a&gt;为何要处理数据倾斜（Data Skew）&lt;/h1&gt;&lt;h2 id=&quot;什么是数据倾斜&quot;&gt;&lt;a href=&quot;#什么是数据倾斜&quot; class=&quot;headerlink&quot; title=&quot;什么是数据倾斜&quot;&gt;&lt;/a&gt;什么是数据倾斜&lt;/h2&gt;&lt;p&gt;对Spark/Hadoop这样的大数据系统来讲，数据量大并不可怕，可怕的是数据倾斜。&lt;/p&gt;
&lt;p&gt;何谓数据倾斜？数据倾斜指的是，并行处理的数据集中，某一部分（如Spark或Kafka的一个Partition）的数据显著多于其它部分，从而使得该部分的处理速度成为整个数据集处理的瓶颈。&lt;/p&gt;
&lt;p&gt;对于分布式系统而言，理想情况下，随着系统规模（节点数量）的增加，应用整体耗时线性下降。如果一台机器处理一批大量数据需要120分钟，当机器数量增加到三时，理想的耗时为120 / 3 = 40分钟，如下图所示&lt;/p&gt;
&lt;p&gt;但是，上述情况只是理想情况，实际上将单机任务转换成分布式任务后，会有overhead，使得总的任务量较之单机时有所增加，所以每台机器的执行时间加起来比单台机器时更大。这里暂不考虑这些overhead，假设单机任务转换成分布式任务后，总任务量不变。&lt;br&gt;　　&lt;br&gt;但即使如此，想做到分布式情况下每台机器执行时间是单机时的，就必须保证每台机器的任务量相等。不幸的是，很多时候，任务的分配是不均匀的，甚至不均匀到大部分任务被分配到个别机器上，其它大部分机器所分配的任务量只占总得的小部分。比如一台机器负责处理80%的任务，另外两台机器各处理10%的任务，如下图所示&lt;br&gt;&lt;a href=&quot;http://www.jasongj.com/img/spark/spark1_skew/skew_time.png&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;&lt;img src=&quot;/2020/08/24/Spark%E6%95%B0%E6%8D%AE%E5%80%BE%E6%96%9C%E5%A4%84%E7%90%86%E6%96%B9%E6%B3%95%E6%80%BB%E7%BB%93/skew_time.png&quot; alt=&quot;unideal scale out&quot;&gt;&lt;/a&gt;&lt;/p&gt;
    
    </summary>
    
    
      <category term="Spark" scheme="http://yoursite.com/categories/Spark/"/>
    
    
      <category term="Spark" scheme="http://yoursite.com/tags/Spark/"/>
    
      <category term="数据倾斜" scheme="http://yoursite.com/tags/%E6%95%B0%E6%8D%AE%E5%80%BE%E6%96%9C/"/>
    
  </entry>
  
  <entry>
    <title>Docker介绍</title>
    <link href="http://yoursite.com/2020/08/22/Docker%E4%BB%8B%E7%BB%8D/"/>
    <id>http://yoursite.com/2020/08/22/Docker%E4%BB%8B%E7%BB%8D/</id>
    <published>2020-08-22T03:59:19.000Z</published>
    <updated>2020-08-22T04:27:26.239Z</updated>
    
    <summary type="html">
    
      &lt;p&gt;为了更好的理解 Docker 是什么，我们先来讲个故事：&lt;/p&gt;
&lt;p&gt;我需要盖一个房子，于是我搬石头、砍木头、画图纸、盖房子。一顿操作，终于把这个房子盖好了。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/2020/08/22/Docker%E4%BB%8B%E7%BB%8D/640.png&quot; alt=&quot;img&quot;&gt;&lt;/p&gt;
    
    </summary>
    
    
      <category term="Docker" scheme="http://yoursite.com/categories/Docker/"/>
    
    
      <category term="Docker" scheme="http://yoursite.com/tags/Docker/"/>
    
  </entry>
  
  <entry>
    <title>Spark结构化流-窗口操作与水印</title>
    <link href="http://yoursite.com/2020/08/20/Spark%E7%BB%93%E6%9E%84%E5%8C%96%E6%B5%81-%E7%AA%97%E5%8F%A3%E6%93%8D%E4%BD%9C%E4%B8%8E%E6%B0%B4%E5%8D%B0/"/>
    <id>http://yoursite.com/2020/08/20/Spark%E7%BB%93%E6%9E%84%E5%8C%96%E6%B5%81-%E7%AA%97%E5%8F%A3%E6%93%8D%E4%BD%9C%E4%B8%8E%E6%B0%B4%E5%8D%B0/</id>
    <published>2020-08-20T08:32:22.000Z</published>
    <updated>2020-08-20T09:03:54.300Z</updated>
    
    <summary type="html">
    
      &lt;h3 id=&quot;事件时间窗口操作&quot;&gt;&lt;a href=&quot;#事件时间窗口操作&quot; class=&quot;headerlink&quot; title=&quot;事件时间窗口操作&quot;&gt;&lt;/a&gt;事件时间窗口操作&lt;/h3&gt;&lt;p&gt;滑动事件时间窗口上的聚合对于结构化流而言非常简单，并且与分组聚合非常相似。在分组聚合中，在用户指定的分组列中为每个唯一值维护聚合值（例如，计数）。在基于窗口的聚合的情况下，行事件时间所属的每个窗口都会维护聚合值。让我们通过插图来了解这一点。&lt;/p&gt;
&lt;p&gt;想象一下我们的&lt;a href=&quot;https://spark.apache.org/docs/2.2.0/structured-streaming-programming-guide.html#quick-example&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;快速示例&lt;/a&gt;已被修改，并且流现在包含行以及生成行的时间。而不是运行字数统计，我们希望在10分钟的窗口内对字数进行计数，每5分钟更新一次。也就是说，在10分钟窗口12:00-12：10、12：05-12：15、12：10-12:20等之间接收的单词中的单词计数。请注意，12：00-12:10表示数据12:00之后但12:10之前到达。现在，考虑在12:07收到的单词。此字应增加对应于两个窗口12:00-12:10和12:05-12:15的计数。因此，计数将通过分组键（即单词）和窗口（可以从事件时间计算）来索引。&lt;/p&gt;
&lt;p&gt;结果表如下所示。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/2020/08/20/Spark%E7%BB%93%E6%9E%84%E5%8C%96%E6%B5%81-%E7%AA%97%E5%8F%A3%E6%93%8D%E4%BD%9C%E4%B8%8E%E6%B0%B4%E5%8D%B0/structured-streaming-window.png&quot; alt=&quot;窗口操作&quot;&gt;&lt;/p&gt;
    
    </summary>
    
    
      <category term="spark-structured-streaming" scheme="http://yoursite.com/categories/spark-structured-streaming/"/>
    
    
      <category term="流处理" scheme="http://yoursite.com/tags/%E6%B5%81%E5%A4%84%E7%90%86/"/>
    
      <category term="spark" scheme="http://yoursite.com/tags/spark/"/>
    
      <category term="窗口操作" scheme="http://yoursite.com/tags/%E7%AA%97%E5%8F%A3%E6%93%8D%E4%BD%9C/"/>
    
      <category term="水印操作" scheme="http://yoursite.com/tags/%E6%B0%B4%E5%8D%B0%E6%93%8D%E4%BD%9C/"/>
    
  </entry>
  
  <entry>
    <title>How to Install ClickHouse with RPM packages from Altinity&#39;s repo(s)</title>
    <link href="http://yoursite.com/2020/08/19/How-to-Install-ClickHouse-with-RPM-packages-from-Altinity-s-repo-s/"/>
    <id>http://yoursite.com/2020/08/19/How-to-Install-ClickHouse-with-RPM-packages-from-Altinity-s-repo-s/</id>
    <published>2020-08-19T11:24:41.000Z</published>
    <updated>2020-08-19T11:48:40.197Z</updated>
    
    <summary type="html">
    
      &lt;h2 id=&quot;What-is-this&quot;&gt;&lt;a href=&quot;#What-is-this&quot; class=&quot;headerlink&quot; title=&quot;What is this&quot;&gt;&lt;/a&gt;What is this&lt;/h2&gt;&lt;p&gt;This is a detailed explanation on how to install ready-to-use ClickHouse RPMs from Altinity’s repos (either &lt;a href=&quot;https://packagecloud.io/Altinity/clickhouse&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;general repo&lt;/a&gt; or &lt;a href=&quot;https://packagecloud.io/Altinity/clickhouse-altinity-stable&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;stable repo&lt;/a&gt;) located on &lt;a href=&quot;https://packagecloud.io/Altinity&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;packagecloud.io&lt;/a&gt;. This is &lt;strong&gt;not&lt;/strong&gt; an instructions on how to build your own hand-made RPMs. However, if you need to build your own RPMs, there is a &lt;a href=&quot;https://github.com/Altinity/clickhouse-rpm&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;detailed explanation&lt;/a&gt; on how to build ClickHouse RPMs from sources with the help of Altinity’s &lt;a href=&quot;https://github.com/Altinity/clickhouse-rpm&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;RPM builder&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&quot;Introduction&quot;&gt;&lt;a href=&quot;#Introduction&quot; class=&quot;headerlink&quot; title=&quot;Introduction&quot;&gt;&lt;/a&gt;Introduction&lt;/h2&gt;&lt;h3 id=&quot;general-and-stable-repos&quot;&gt;&lt;a href=&quot;#general-and-stable-repos&quot; class=&quot;headerlink&quot; title=&quot;general and stable repos&quot;&gt;&lt;/a&gt;&lt;code&gt;general&lt;/code&gt; and &lt;code&gt;stable&lt;/code&gt; repos&lt;/h3&gt;&lt;p&gt;Altinity provides two repos:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;code&gt;general&lt;/code&gt; &lt;a href=&quot;https://packagecloud.io/Altinity/clickhouse&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;repo&lt;/a&gt; with general ClickHouse releases.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;code&gt;stable&lt;/code&gt; &lt;a href=&quot;https://packagecloud.io/Altinity/clickhouse-altinity-stable&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;repo&lt;/a&gt; with Altinity Stable ClickHouse releases.&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;
    
    </summary>
    
    
      <category term="ClickHouse" scheme="http://yoursite.com/categories/ClickHouse/"/>
    
    
      <category term="ClickHouse" scheme="http://yoursite.com/tags/ClickHouse/"/>
    
      <category term="安装" scheme="http://yoursite.com/tags/%E5%AE%89%E8%A3%85/"/>
    
  </entry>
  
  <entry>
    <title>Hbase学习2-系统架构与数据结构</title>
    <link href="http://yoursite.com/2020/08/17/Hbase%E5%AD%A6%E4%B9%A0-2-%E7%B3%BB%E7%BB%9F%E6%9E%B6%E6%9E%84%E4%B8%8E%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"/>
    <id>http://yoursite.com/2020/08/17/Hbase%E5%AD%A6%E4%B9%A0-2-%E7%B3%BB%E7%BB%9F%E6%9E%B6%E6%9E%84%E4%B8%8E%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/</id>
    <published>2020-08-17T09:23:29.000Z</published>
    <updated>2020-08-17T09:28:53.761Z</updated>
    
    <summary type="html">
    
      &lt;h2 id=&quot;一、基本概念&quot;&gt;&lt;a href=&quot;#一、基本概念&quot; class=&quot;headerlink&quot; title=&quot;一、基本概念&quot;&gt;&lt;/a&gt;一、基本概念&lt;/h2&gt;&lt;p&gt;一个典型的 Hbase Table 表如下：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/2020/08/17/Hbase%E5%AD%A6%E4%B9%A0-2-%E7%B3%BB%E7%BB%9F%E6%9E%B6%E6%9E%84%E4%B8%8E%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/image-20200817172516439.png&quot; alt=&quot;image-20200817172516439&quot;&gt;&lt;/p&gt;
    
    </summary>
    
    
      <category term="Hbase" scheme="http://yoursite.com/categories/Hbase/"/>
    
    
      <category term="Hbase" scheme="http://yoursite.com/tags/Hbase/"/>
    
      <category term="学习笔记" scheme="http://yoursite.com/tags/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
  </entry>
  
  <entry>
    <title>spark-streaming学习1</title>
    <link href="http://yoursite.com/2020/08/17/spark-streaming%E5%AD%A6%E4%B9%A01/"/>
    <id>http://yoursite.com/2020/08/17/spark-streaming%E5%AD%A6%E4%B9%A01/</id>
    <published>2020-08-17T09:11:45.000Z</published>
    <updated>2020-08-17T09:15:35.509Z</updated>
    
    <summary type="html">
    
      &lt;h2 id=&quot;一、流处理&quot;&gt;&lt;a href=&quot;#一、流处理&quot; class=&quot;headerlink&quot; title=&quot;一、流处理&quot;&gt;&lt;/a&gt;一、流处理&lt;/h2&gt;&lt;h3 id=&quot;1-1-静态数据处理&quot;&gt;&lt;a href=&quot;#1-1-静态数据处理&quot; class=&quot;headerlink&quot; title=&quot;1.1 静态数据处理&quot;&gt;&lt;/a&gt;1.1 静态数据处理&lt;/h3&gt;&lt;p&gt;在流处理之前，数据通常存储在数据库，文件系统或其他形式的存储系统中。应用程序根据需要查询数据或计算数据。这就是传统的静态数据处理架构。Hadoop 采用 HDFS 进行数据存储，采用 MapReduce 进行数据查询或分析，这就是典型的静态数据处理架构。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/2020/08/17/spark-streaming%E5%AD%A6%E4%B9%A01/image-20200817171353524.png&quot; alt=&quot;image-20200817171353524&quot;&gt;&lt;/p&gt;
    
    </summary>
    
    
      <category term="spark streaming" scheme="http://yoursite.com/categories/spark-streaming/"/>
    
    
      <category term="流处理" scheme="http://yoursite.com/tags/%E6%B5%81%E5%A4%84%E7%90%86/"/>
    
      <category term="spark" scheme="http://yoursite.com/tags/spark/"/>
    
  </entry>
  
  <entry>
    <title>学习知乎实时数仓实践及架构演进</title>
    <link href="http://yoursite.com/2020/08/12/%E5%AD%A6%E4%B9%A0%E7%9F%A5%E4%B9%8E%E5%AE%9E%E6%97%B6%E6%95%B0%E4%BB%93%E5%AE%9E%E8%B7%B5%E5%8F%8A%E6%9E%B6%E6%9E%84%E6%BC%94%E8%BF%9B/"/>
    <id>http://yoursite.com/2020/08/12/%E5%AD%A6%E4%B9%A0%E7%9F%A5%E4%B9%8E%E5%AE%9E%E6%97%B6%E6%95%B0%E4%BB%93%E5%AE%9E%E8%B7%B5%E5%8F%8A%E6%9E%B6%E6%9E%84%E6%BC%94%E8%BF%9B/</id>
    <published>2020-08-12T02:49:20.000Z</published>
    <updated>2020-08-12T03:29:14.864Z</updated>
    
    <summary type="html">
    
      &lt;h1 id=&quot;前言&quot;&gt;&lt;a href=&quot;#前言&quot; class=&quot;headerlink&quot; title=&quot;前言&quot;&gt;&lt;/a&gt;前言&lt;/h1&gt;&lt;p&gt;“数据智能” (Data Intelligence) 有一个必须且基础的环节，就是数据仓库的建设，同时，数据仓库也是公司数据发展到一定规模后必然会提供的一种基础服务。从智能商业的角度来讲，数据的结果代表了用户的反馈，获取结果的及时性就显得尤为重要，快速的获取数据反馈能够帮助公司更快的做出决策，更好的进行产品迭代，实时数仓在这一过程中起到了不可替代的作用。&lt;/p&gt;
&lt;p&gt;本文主要讲述知乎的实时数仓实践以及架构的演进，这包括以下几个方面&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;p&gt;实时数仓 1.0 版本，主题： ETL 逻辑实时化，技术方案：Spark Streaming。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;实时数仓 2.0 版本，主题：数据分层，指标计算实时化，技术方案：Flink Streaming。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;实时数仓未来展望：Streaming SQL 平台化，元信息管理系统化，结果验收自动化。&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;
    
    </summary>
    
    
      <category term="实时数仓" scheme="http://yoursite.com/categories/%E5%AE%9E%E6%97%B6%E6%95%B0%E4%BB%93/"/>
    
    
      <category term="学习笔记" scheme="http://yoursite.com/tags/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
      <category term="实时计算" scheme="http://yoursite.com/tags/%E5%AE%9E%E6%97%B6%E8%AE%A1%E7%AE%97/"/>
    
      <category term="实时数仓" scheme="http://yoursite.com/tags/%E5%AE%9E%E6%97%B6%E6%95%B0%E4%BB%93/"/>
    
  </entry>
  
  <entry>
    <title>实时数仓</title>
    <link href="http://yoursite.com/2020/08/11/%E5%AE%9E%E6%97%B6%E6%95%B0%E4%BB%93/"/>
    <id>http://yoursite.com/2020/08/11/%E5%AE%9E%E6%97%B6%E6%95%B0%E4%BB%93/</id>
    <published>2020-08-11T03:47:16.000Z</published>
    <updated>2020-08-11T05:43:03.618Z</updated>
    
    <summary type="html">
    
      &lt;h3 id=&quot;0x00-数仓为什么要实时&quot;&gt;&lt;a href=&quot;#0x00-数仓为什么要实时&quot; class=&quot;headerlink&quot; title=&quot;|0x00 数仓为什么要实时&quot;&gt;&lt;/a&gt;|0x00 数仓为什么要实时&lt;/h3&gt;&lt;p&gt;去年开始，&lt;font color=&quot;red&quot;&gt;实时数仓&lt;/font&gt; 的概念突然火了。也许是&lt;strong&gt;传统的离线数仓搞了很多年&lt;/strong&gt;，技术相对成熟了，因此大家都把注意力放到了&lt;strong&gt;挑战性更高&lt;/strong&gt;的实时上来；也许是随着&lt;strong&gt;存量市场竞争&lt;/strong&gt;的到来，对于速度的要求越来越快，&lt;strong&gt;T+1已经不能满足数据的获取要求了&lt;/strong&gt;，实时的构建需求也就应运而生了。 &lt;/p&gt;
&lt;p&gt;&lt;font color=&quot;red&quot;&gt;总之，时效性开始大于分析性&lt;/font&gt; 。&lt;/p&gt;
&lt;p&gt;文本简单介绍实时数仓的一些基础理论，更系统性的理论，仍然行业需要更大范围的应用和总结。总之，这是一块&lt;strong&gt;有前景&lt;/strong&gt;的&lt;strong&gt;新领域&lt;/strong&gt;，值得探索。&lt;/p&gt;
    
    </summary>
    
    
      <category term="实时数仓" scheme="http://yoursite.com/categories/%E5%AE%9E%E6%97%B6%E6%95%B0%E4%BB%93/"/>
    
    
      <category term="数仓" scheme="http://yoursite.com/tags/%E6%95%B0%E4%BB%93/"/>
    
      <category term="实时" scheme="http://yoursite.com/tags/%E5%AE%9E%E6%97%B6/"/>
    
  </entry>
  
  <entry>
    <title>Hbase学习笔记-1</title>
    <link href="http://yoursite.com/2020/08/04/Hbase%E7%AC%94%E8%AE%B0-1/"/>
    <id>http://yoursite.com/2020/08/04/Hbase%E7%AC%94%E8%AE%B0-1/</id>
    <published>2020-08-04T11:47:45.000Z</published>
    <updated>2020-08-07T10:30:45.607Z</updated>
    
    <summary type="html">
    
      &lt;h2 id=&quot;一-Hadoop的局限性&quot;&gt;&lt;a href=&quot;#一-Hadoop的局限性&quot; class=&quot;headerlink&quot; title=&quot;一.Hadoop的局限性&quot;&gt;&lt;/a&gt;一.Hadoop的局限性&lt;/h2&gt;&lt;p&gt;Hbase是一个构建在Hadoop文件系统之上的面向列(列族)的数据库管理系统&lt;/p&gt;
&lt;img src=&quot;/2020/08/04/Hbase%E7%AC%94%E8%AE%B0-1/image-20200804194929543.png&quot; alt=&quot;image-20200804194929543&quot; style=&quot;zoom:50%;&quot;&gt;
    
    </summary>
    
    
      <category term="Hbase" scheme="http://yoursite.com/categories/Hbase/"/>
    
    
      <category term="Hbase" scheme="http://yoursite.com/tags/Hbase/"/>
    
      <category term="学习笔记" scheme="http://yoursite.com/tags/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
  </entry>
  
  <entry>
    <title>MapReduce小文件优化问题</title>
    <link href="http://yoursite.com/2020/08/04/MapReduce%E5%B0%8F%E6%96%87%E4%BB%B6%E4%BC%98%E5%8C%96%E9%97%AE%E9%A2%98/"/>
    <id>http://yoursite.com/2020/08/04/MapReduce%E5%B0%8F%E6%96%87%E4%BB%B6%E4%BC%98%E5%8C%96%E9%97%AE%E9%A2%98/</id>
    <published>2020-08-04T11:42:41.000Z</published>
    <updated>2020-08-04T11:45:19.506Z</updated>
    
    <summary type="html">
    
      &lt;p&gt;默认情况下，TextInputformat对任务的切片机智是按文件规划切片，不管文件多小，都会是一个单独的切片，都是交给一个maptask，如果有多个小文件，就会产生大量的maptask，处理效率底下。&lt;/p&gt;
    
    </summary>
    
    
      <category term="MapReduce" scheme="http://yoursite.com/categories/MapReduce/"/>
    
    
      <category term="优化" scheme="http://yoursite.com/tags/%E4%BC%98%E5%8C%96/"/>
    
  </entry>
  
  <entry>
    <title>机器学习项目01-鸢尾花分类</title>
    <link href="http://yoursite.com/2020/07/24/ML-flower/"/>
    <id>http://yoursite.com/2020/07/24/ML-flower/</id>
    <published>2020-07-24T10:32:57.000Z</published>
    <updated>2020-07-24T11:20:42.263Z</updated>
    
    <summary type="html">
    
      &lt;p&gt;机器学习项目之鸢尾花分类:&lt;/p&gt;
&lt;h3 id=&quot;任务描述&quot;&gt;&lt;a href=&quot;#任务描述&quot; class=&quot;headerlink&quot; title=&quot;任务描述:&quot;&gt;&lt;/a&gt;任务描述:&lt;/h3&gt;&lt;p&gt;构建一个模型，根据鸢尾花的花萼和花瓣大小将其分为三种不同的品种。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/2020/07/24/ML-flower/dd74666475b549fcae99ac2aff67488f015cdd76569d4d208909983bcf40fe3c.png&quot; alt=&quot;dd74666475b549fcae99ac2aff67488f015cdd76569d4d208909983bcf40fe3c&quot;&gt;&lt;/p&gt;
    
    </summary>
    
    
      <category term="机器学习" scheme="http://yoursite.com/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="鸢尾花分类" scheme="http://yoursite.com/tags/%E9%B8%A2%E5%B0%BE%E8%8A%B1%E5%88%86%E7%B1%BB/"/>
    
      <category term="机器学习" scheme="http://yoursite.com/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="Notebook" scheme="http://yoursite.com/tags/Notebook/"/>
    
  </entry>
  
  <entry>
    <title>同比与环比</title>
    <link href="http://yoursite.com/2020/07/24/%E5%90%8C%E6%AF%94%E7%8E%AF%E6%AF%94/"/>
    <id>http://yoursite.com/2020/07/24/%E5%90%8C%E6%AF%94%E7%8E%AF%E6%AF%94/</id>
    <published>2020-07-24T10:12:57.000Z</published>
    <updated>2020-07-24T11:07:04.052Z</updated>
    
    <summary type="html">
    
      &lt;h2 id=&quot;概念&quot;&gt;&lt;a href=&quot;#概念&quot; class=&quot;headerlink&quot; title=&quot;概念&quot;&gt;&lt;/a&gt;概念&lt;/h2&gt;&lt;p&gt;同比：本期与同期做对比。&lt;/p&gt;
&lt;p&gt;环比：本期与上期做对比。&lt;/p&gt;
&lt;p&gt;简单点说，同比和环比用于表示某一事物在对比时期内发展变化的方向和程度。以历史同期为基期，例如2016年2月份与2015年2月份、2016年上半年与2015年上半年的比较，就是同比。以前一个统计时间段为基期，例如2016年6月份与2016年5月份、2016年二季度与2016年一季度的比较，就是环比。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/2020/07/24/%E5%90%8C%E6%AF%94%E7%8E%AF%E6%AF%94/c5EoSijy31QIDAx.png&quot; alt=&quot;c5EoSijy31QIDAx&quot;&gt;&lt;/p&gt;
    
    </summary>
    
    
      <category term="数据" scheme="http://yoursite.com/categories/%E6%95%B0%E6%8D%AE/"/>
    
    
      <category term="同比/环比" scheme="http://yoursite.com/tags/%E5%90%8C%E6%AF%94-%E7%8E%AF%E6%AF%94/"/>
    
  </entry>
  
  <entry>
    <title>mac连接公司vpn的坑</title>
    <link href="http://yoursite.com/2020/07/24/mac%E8%BF%9E%E6%8E%A5%E5%85%AC%E5%8F%B8VPN%E7%9A%84%E5%9D%91/"/>
    <id>http://yoursite.com/2020/07/24/mac%E8%BF%9E%E6%8E%A5%E5%85%AC%E5%8F%B8VPN%E7%9A%84%E5%9D%91/</id>
    <published>2020-07-24T09:12:57.000Z</published>
    <updated>2020-07-24T11:18:28.001Z</updated>
    
    <summary type="html">
    
      &lt;h3 id=&quot;问题&quot;&gt;&lt;a href=&quot;#问题&quot; class=&quot;headerlink&quot; title=&quot;问题&quot;&gt;&lt;/a&gt;问题&lt;/h3&gt;&lt;p&gt;1.出现IPSec共享密匙丢失&lt;/p&gt;
&lt;p&gt;2.能访问公司内网,无法访问公网&lt;/p&gt;
    
    </summary>
    
    
      <category term="公司vpn" scheme="http://yoursite.com/categories/%E5%85%AC%E5%8F%B8vpn/"/>
    
    
      <category term="远程访问" scheme="http://yoursite.com/tags/%E8%BF%9C%E7%A8%8B%E8%AE%BF%E9%97%AE/"/>
    
      <category term="公司vpn" scheme="http://yoursite.com/tags/%E5%85%AC%E5%8F%B8vpn/"/>
    
  </entry>
  
  <entry>
    <title>hive on spark与spark on hive的区别</title>
    <link href="http://yoursite.com/2020/07/23/Hive-on-Spark%E4%B8%8ESparkSql%E7%9A%84%E5%8C%BA%E5%88%AB/"/>
    <id>http://yoursite.com/2020/07/23/Hive-on-Spark%E4%B8%8ESparkSql%E7%9A%84%E5%8C%BA%E5%88%AB/</id>
    <published>2020-07-23T09:12:57.000Z</published>
    <updated>2020-07-24T11:15:36.500Z</updated>
    
    <summary type="html">
    
      &lt;h3 id=&quot;SparkSQL简介&quot;&gt;&lt;a href=&quot;#SparkSQL简介&quot; class=&quot;headerlink&quot; title=&quot;SparkSQL简介&quot;&gt;&lt;/a&gt;SparkSQL简介&lt;/h3&gt;&lt;p&gt;SparkSQL的前身是Shark，给熟悉RDBMS但又不理解MapReduce的技术人员提供快速上手的工具，hive应运而生，它是当时唯一运行在Hadoop上的SQL-on-hadoop工具。但是MapReduce计算过程中大量的中间磁盘落地过程消耗了大量的I/O，降低的运行效率，为了提高SQL-on-Hadoop的效率，Shark应运而生，但又因为Shark对于Hive的太多依赖（如采用Hive的语法解析器、查询优化器等等),2014年spark团队停止对Shark的开发，将所有资源放SparkSQL项目上&lt;/p&gt;
    
    </summary>
    
    
      <category term="Hive" scheme="http://yoursite.com/categories/Hive/"/>
    
    
      <category term="hive on spark" scheme="http://yoursite.com/tags/hive-on-spark/"/>
    
      <category term="spark on hive" scheme="http://yoursite.com/tags/spark-on-hive/"/>
    
  </entry>
  
  <entry>
    <title>hive两个聚合函数的计算结果拼接成表并做进一步计算</title>
    <link href="http://yoursite.com/2020/07/23/%E4%B8%A4%E4%B8%AA%E8%81%9A%E5%90%88%E5%87%BD%E6%95%B0%E8%AE%A1%E7%AE%97%E7%BB%93%E6%9E%9C%E8%BF%9B%E8%A1%8C%E6%8B%BC%E6%8E%A5/"/>
    <id>http://yoursite.com/2020/07/23/%E4%B8%A4%E4%B8%AA%E8%81%9A%E5%90%88%E5%87%BD%E6%95%B0%E8%AE%A1%E7%AE%97%E7%BB%93%E6%9E%9C%E8%BF%9B%E8%A1%8C%E6%8B%BC%E6%8E%A5/</id>
    <published>2020-07-23T04:12:57.000Z</published>
    <updated>2020-07-23T03:51:12.106Z</updated>
    
    <summary type="html">
    
      &lt;h4 id=&quot;hive两个聚合函数的计算结果拼接成表并做进一步计算&quot;&gt;&lt;a href=&quot;#hive两个聚合函数的计算结果拼接成表并做进一步计算&quot; class=&quot;headerlink&quot; title=&quot;hive两个聚合函数的计算结果拼接成表并做进一步计算&quot;&gt;&lt;/a&gt;hive两个聚合函数的计算结果拼接成表并做进一步计算&lt;/h4&gt;&lt;p&gt;hive两个聚合函数的计算结果拼接成表让LZ头疼了很久，一度想到用python处理，或者新建两张临时表保存聚合函数的结果然后再取出数据进行计算，或者使用UDF, 但总觉得还有其他方法。经过一番探索，发现WITH AS 可以方便快捷解决此问题。&lt;/p&gt;
    
    </summary>
    
    
      <category term="Hive" scheme="http://yoursite.com/categories/Hive/"/>
    
    
      <category term="hive" scheme="http://yoursite.com/tags/hive/"/>
    
      <category term="函数" scheme="http://yoursite.com/tags/%E5%87%BD%E6%95%B0/"/>
    
  </entry>
  
  <entry>
    <title>Parquet列式存储格式</title>
    <link href="http://yoursite.com/2020/07/22/parquet%E5%88%97%E5%BC%8F%E5%AD%98%E5%82%A8%E6%A0%BC%E5%BC%8F/"/>
    <id>http://yoursite.com/2020/07/22/parquet%E5%88%97%E5%BC%8F%E5%AD%98%E5%82%A8%E6%A0%BC%E5%BC%8F/</id>
    <published>2020-07-22T11:40:53.000Z</published>
    <updated>2020-07-22T11:41:15.332Z</updated>
    
    <summary type="html">
    
      &lt;p&gt;Parquet是面向分析型业务的列式存储格式，由Twitter和Cloudera合作开发，2015年5月从Apache的孵化器里毕业成为Apache顶级项目，最新的版本是1.8.0。&lt;/p&gt;
    
    </summary>
    
    
      <category term="Parquet" scheme="http://yoursite.com/categories/Parquet/"/>
    
    
      <category term="hive" scheme="http://yoursite.com/tags/hive/"/>
    
      <category term="Parquet" scheme="http://yoursite.com/tags/Parquet/"/>
    
  </entry>
  
  <entry>
    <title>Hive中Parquet格式的使用</title>
    <link href="http://yoursite.com/2020/07/22/Hive%E4%B8%ADParquet%E6%A0%BC%E5%BC%8F%E7%9A%84%E4%BD%BF%E7%94%A8/"/>
    <id>http://yoursite.com/2020/07/22/Hive%E4%B8%ADParquet%E6%A0%BC%E5%BC%8F%E7%9A%84%E4%BD%BF%E7%94%A8/</id>
    <published>2020-07-22T11:38:48.000Z</published>
    <updated>2020-07-22T11:40:19.675Z</updated>
    
    <summary type="html">
    
      &lt;h1 id=&quot;Hive中Parquet格式的使用&quot;&gt;&lt;a href=&quot;#Hive中Parquet格式的使用&quot; class=&quot;headerlink&quot; title=&quot;Hive中Parquet格式的使用&quot;&gt;&lt;/a&gt;Hive中Parquet格式的使用&lt;/h1&gt;&lt;p&gt;&lt;strong&gt;#Hive建外部External表（外部表external table）：&lt;/strong&gt;&lt;/p&gt;
&lt;figure class=&quot;highlight sql&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;12&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;13&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;14&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;15&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;CREATE&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;EXTERNAL&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;TABLE&lt;/span&gt; &lt;span class=&quot;string&quot;&gt;`table_name`&lt;/span&gt;(&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;  &lt;span class=&quot;string&quot;&gt;`column1`&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;string&lt;/span&gt;,&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;  &lt;span class=&quot;string&quot;&gt;`column2`&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;string&lt;/span&gt;,&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;  &lt;span class=&quot;string&quot;&gt;`column3`&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;string&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;PARTITIONED &lt;span class=&quot;keyword&quot;&gt;BY&lt;/span&gt; (&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;  &lt;span class=&quot;string&quot;&gt;`proc_date`&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;string&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;ROW&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;FORMAT&lt;/span&gt; SERDE&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;  &lt;span class=&quot;string&quot;&gt;&#39;org.apache.hadoop.hive.ql.io.parquet.serde.ParquetHiveSerDe&#39;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;STORED&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;AS&lt;/span&gt; INPUTFORMAT&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;  &lt;span class=&quot;string&quot;&gt;&#39;org.apache.hadoop.hive.ql.io.parquet.MapredParquetInputFormat&#39;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;OUTPUTFORMAT&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;  &lt;span class=&quot;string&quot;&gt;&#39;org.apache.hadoop.hive.ql.io.parquet.MapredParquetOutputFormat&#39;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;LOCATION&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;  &lt;span class=&quot;string&quot;&gt;&#39;hdfs://hdfscluster/...&#39;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;TBLPROPERTIES ( &lt;span class=&quot;string&quot;&gt;&#39;orc.compress&#39;&lt;/span&gt;=&lt;span class=&quot;string&quot;&gt;&#39;snappy&#39;&lt;/span&gt;);&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
    
    </summary>
    
    
      <category term="Hive" scheme="http://yoursite.com/categories/Hive/"/>
    
    
      <category term="hive" scheme="http://yoursite.com/tags/hive/"/>
    
      <category term="Parquet" scheme="http://yoursite.com/tags/Parquet/"/>
    
  </entry>
  
  <entry>
    <title>Python时间操作</title>
    <link href="http://yoursite.com/2020/07/22/python%E6%97%B6%E9%97%B4/"/>
    <id>http://yoursite.com/2020/07/22/python%E6%97%B6%E9%97%B4/</id>
    <published>2020-07-22T11:34:19.000Z</published>
    <updated>2020-07-22T11:37:39.354Z</updated>
    
    <summary type="html">
    
      &lt;figure class=&quot;highlight python&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;import&lt;/span&gt; time&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;print&lt;/span&gt; time.time()	&lt;span class=&quot;comment&quot;&gt;#输出的结果是:1279578704.6725271&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
    
    </summary>
    
    
      <category term="语言" scheme="http://yoursite.com/categories/%E8%AF%AD%E8%A8%80/"/>
    
    
      <category term="python" scheme="http://yoursite.com/tags/python/"/>
    
  </entry>
  
  <entry>
    <title>Sqoop从mysql导入数据到hive</title>
    <link href="http://yoursite.com/2020/07/22/sqoop%E4%BB%8Emysql%E5%AF%BC%E5%85%A5%E6%95%B0%E6%8D%AE%E5%88%B0hive/"/>
    <id>http://yoursite.com/2020/07/22/sqoop%E4%BB%8Emysql%E5%AF%BC%E5%85%A5%E6%95%B0%E6%8D%AE%E5%88%B0hive/</id>
    <published>2020-07-22T06:12:02.000Z</published>
    <updated>2020-07-22T06:25:09.346Z</updated>
    
    <summary type="html">
    
      &lt;h2 id=&quot;一、简介&quot;&gt;&lt;a href=&quot;#一、简介&quot; class=&quot;headerlink&quot; title=&quot;一、简介&quot;&gt;&lt;/a&gt;一、简介&lt;/h2&gt;&lt;p&gt;Sqoop是一个用来将Hadoop和关系型数据库中的数据相互转移的工具，可以将一个关系型数据库（例如 ： MySQL ,Oracle ,Postgres等）中的数据导进到Hadoop的HDFS中，也可以将HDFS的数据导进到关系型数据库中。Sqoop专为大数据批量传输设计，能够分割数据集并创建Hadoop任务来处理每个区块。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;把MySQL、Oracle等数据库中的数据导入到HDFS、Hive、HBase中。
把HDFS、Hive、HBase中的数据导出到MySQL、Oracle等数据库中。
1.4 为sqoop1, 1.9 为sqoop2 ，sqoop1与sqoop2是不兼容的。&lt;/code&gt;&lt;/pre&gt;
    
    </summary>
    
    
      <category term="Sqoop" scheme="http://yoursite.com/categories/Sqoop/"/>
    
    
      <category term="hive" scheme="http://yoursite.com/tags/hive/"/>
    
      <category term="Sqoop" scheme="http://yoursite.com/tags/Sqoop/"/>
    
      <category term="mysql" scheme="http://yoursite.com/tags/mysql/"/>
    
  </entry>
  
</feed>
